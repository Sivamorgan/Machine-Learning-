{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Supplement 6: Decision Trees and Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from scipy.stats import mode\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Programming Task: Song popularity prediction using Random Forest\n",
        "The goal of this task is to train a random forest model that predicts the song popularity using the datasets already provided in task 4.3\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read data\n",
        "\n",
        "#TODO\n",
        "train_data=pd.read_csv('./train-songs.csv')\n",
        "test_data=pd.read_csv('./test-songs.csv')\n",
        "\n",
        "train_X = train_data.drop(columns=['popular']).to_numpy()\n",
        "train_y = train_data['popular'].to_numpy()\n",
        "test_X = test_data.drop(columns=['popular']).to_numpy()\n",
        "test_y = test_data['popular'].to_numpy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "   i\\. Implement a function that draws a bootstrap sample of size N from the train dataset, where N can be specified by the user.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def generate_bootstrap(train_X,train_y,N,random_state=None):\n",
        "   rng=np.random.RandomState(random_state)\n",
        "   indices=rng.choice(len(train_X),size=N,replace=True)\n",
        "   bootstraped_X=train_X[indices]\n",
        "   bootstraped_y=train_y[indices]\n",
        "   return bootstraped_X,bootstraped_y\n",
        "\n",
        "\n",
        "bootstrapped_X,bootstrapped_y=generate_bootstrap(train_X,train_y,5)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "   ii\\. Complete the implementation of the random forest algorithm. For this task you may use the DecisionTreeClassifier from the scikit-learn library. The other parts of the random forest algorithm must be implemented using only Scipy/Numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RandomForest:\n",
        "   def __init__(self,n_trees,max_features,max_samples,min_node_size, max_depth):\n",
        "\n",
        "      #TODO Initialize list containing weak classifiers. Also initialize any other parameter if required.\n",
        "      self.n_trees=n_trees\n",
        "      self.max_features=max_features\n",
        "      self.max_samples=max_samples\n",
        "      self.min_node_size=min_node_size\n",
        "      self.max_depth=max_depth\n",
        "      self.trees=[]\n",
        "\n",
        "\n",
        "\n",
        "   def train(self,train_X,train_y):\n",
        "      #TODO Training each weak classifier\n",
        "      for i in range(self.n_trees):\n",
        "         bootstrapped_X,bootstrapped_y=generate_bootstrap(train_X,train_y,self.max_samples)\n",
        "         weak_tree=tree.DecisionTreeClassifier(max_depth=self.max_depth,min_samples_leaf=self.min_node_size,max_features=self.max_features)\n",
        "         weak_tree.fit(bootstrapped_X,bootstrapped_y)\n",
        "         self.trees.append(weak_tree)\n",
        "\n",
        "   \n",
        "   def predict(self,test_X):\n",
        "      #TODO Final predictions are obtained by taking majority-vote (most frequent class) from each weak classifier prediction\n",
        "      weak_preds=np.array([weak_tree.predict(test_X) for weak_tree in self.trees])\n",
        "      y_predictions=mode(weak_preds,keepdims=True).mode.flatten()\n",
        "      return y_predictions\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "iii\\. Train the model for the dataset from train-songs.csv using the parameters given below.\n",
        "| Parameter| Value|\n",
        "|----------|------|\n",
        "Number of trees|100|\n",
        "Maximum features per tree|2|\n",
        "Bootstrap sample size|20000|\n",
        "Minimum node size|1|\n",
        "Maximum tree depth|10|\n",
        "\n",
        "\n",
        "Note: The bootstrap sample size is the same as train dataset size in this task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: Run this cell without any changes. The model will train if the implementation of subtask (ii) is correct.\n",
        "random_forest_model = RandomForest(n_trees=100, max_samples=20000,max_depth=10,min_node_size=1, max_features=2 )\n",
        "\n",
        "random_forest_model.train(train_X, train_y)\n",
        "\n",
        "\n",
        "predictions=random_forest_model.predict(test_X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "   iv\\. Calculate the accuracy of the model using the test dataset and compare your results with the\n",
        "RandomForestClassifier from the scikit-learn library using the following parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.805\n"
          ]
        }
      ],
      "source": [
        "# TODO Run predict for test data and calculate accuracy\n",
        "def accuracy(y_true,y_predict):\n",
        "    return np.sum(y_true==y_predict)/len(y_true)\n",
        "\n",
        "print(accuracy(test_y,predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.805\n"
          ]
        }
      ],
      "source": [
        "# TODO: Train and predict using scikit-learn library\n",
        "rf_model_sklearn=RandomForestClassifier(100,max_depth=10,min_samples_leaf=1,max_features=2,max_samples=20000)\n",
        "rf_model_sklearn.fit(train_X,train_y)\n",
        "predic_sklearn=rf_model_sklearn.predict(test_X)\n",
        "print(accuracy(test_y,predic_sklearn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
