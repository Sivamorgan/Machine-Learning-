{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplement 4: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Programming Task: Gaussian Naive-Bayes Classifier\n",
    "The Iris dataset, containing measurements of the flower parts obtained from 3 different species of the Iris plant, is provided in the file __iris.csv__. The first four columns of the dataset contain the measurement values representing input features for the model and the last column contains class labels of the plant species: Iris-setosa, Iris-versicolor, and Iris-virginica.\n",
    "The goal of this task is to implement a Gaussian Naive-Bayes classifier for the Iris dataset.\n",
    "\n",
    "i\\. What are the assumptions on the dataset required for the Gaussian Naive-Bayes model?\n",
    "\n",
    "ii\\. Split the dataset into train and test by the 80:20 ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 120 30\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('./iris.csv')\n",
    "\n",
    "# i. Given the class the features are conditionally independent i.e product(p(x1,x2...xn|y=k)=p(x1|y=k)*....p(xn|y=k)\n",
    "train_length=int(0.8*len(data))\n",
    "train_data=data[:train_length]\n",
    "test_data=data[train_length:]\n",
    "print(len(data),len(train_data),len(test_data))\n",
    "def to_numpy(X):\n",
    "    return X.to_numpy()\n",
    "\n",
    "x_train,y_train,x_test,y_test=train_data.drop(columns=[\"Species\"]),train_data[\"Species\"],test_data.drop(columns=[\"Species\"]),test_data[\"Species\"]\n",
    "x_train_np,x_test_np=to_numpy(x_train),to_numpy(x_test)\n",
    "unique_classes=y_train.unique()\n",
    "str_to_int={cls:idx+1 for idx,cls in enumerate(unique_classes)}\n",
    "y_train_int,y_test_int=y_train.map(str_to_int),y_test.map(str_to_int)\n",
    "y_train_np,y_test_np=to_numpy(y_train_int),to_numpy(y_test_int)\n",
    "print(np.unique(y_train_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii\\. Estimate the parameters of the Gaussian Naive-Bayes classifier using the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mean_var_prior(X,Y):\n",
    "    classes=np.unique(Y)\n",
    "    mean,Var,Prior={},{},{}\n",
    "    for cls in classes:\n",
    "        X_cls=X[Y==cls]\n",
    "        mean[cls]=np.mean(X_cls,axis=0)\n",
    "        Var[cls]=np.cov(X_cls,rowvar=False)\n",
    "        Prior[cls]=len(X_cls)/len(Y)\n",
    "    return mean,Var,Prior\n",
    "    \n",
    "\n",
    "def multivariate_gaussian(X,mean,cov):\n",
    "    d=X.shape[-1]\n",
    "    det=np.linalg.det(cov)\n",
    "    normalizer=1/(np.power((2*np.pi),float(d/2))*np.power(det,1./2))\n",
    "    x_mu=X-mean\n",
    "    inv=np.linalg.inv(cov)\n",
    "    p_X=normalizer*np.exp(-0.5*(x_mu.T@inv@x_mu))\n",
    "    return p_X\n",
    "\n",
    "def predict(X,mean,Var,Prior):\n",
    "    classes=list(mean.keys())\n",
    "    predictions=[]\n",
    "    for x in X:\n",
    "        class_probs={}\n",
    "        for cls in classes:\n",
    "            p_x_given_cls=multivariate_gaussian(x,mean[cls],Var[cls])\n",
    "            class_probs[cls]=p_x_given_cls*Prior[cls]\n",
    "        predicted_class=max(class_probs,key=class_probs.get)\n",
    "        predictions.append(predicted_class)\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "Mean,Var,Prior=mean_var_prior(x_train_np,y_train_np)\n",
    "predictions=predict(x_train_np,Mean,Var,Prior)\n",
    "accuracy=np.sum(y_train_np==predictions)/len(y_train_np)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv\\. Using the learned parameters, predict the classes for the samples in the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions=predict(x_test_np,Mean,Var,Prior)\n",
    "accuracy=np.sum(y_test_np==predictions)/len(y_test_np)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the accuracy of the model on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "model=GaussianNB()\n",
    "model.fit(x_train_np,y_train_np)\n",
    "pred=model.predict(x_test_np)\n",
    "accuracy=accuracy_score(y_test_np,pred)\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
