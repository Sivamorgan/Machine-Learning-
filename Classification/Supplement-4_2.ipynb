{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplement 4: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Programming Task: K-Nearest Neighbor\n",
    "The datasets in files __train-knn.csv__ and __test-knn.csv__ contain samples from a synthetic dataset for training a K-Nearest Neighbor classifier.\n",
    "The dataset consists of 7 columns: the first six columns, denoted as x1, x2, ..., x6 represent\n",
    " the input features for each data sample, and the last column represents the class label given by 0 or 1.\n",
    "There are 200 samples in the __train-knn.csv__ and 100 samples in the __test-knn.csv__}.\n",
    "\n",
    "i\\. Implement the K-Nearest Neighbor classification algorithm using NumPy and SciPy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "training_data=pd.read_csv('./train-knn.csv')\n",
    "X_train=training_data.drop(columns=['class']).to_numpy()\n",
    "y_train=training_data.pop('class').to_numpy()\n",
    "num_neighbors = 3\n",
    "class kNearestNeighbor(object):\n",
    "    def __init__(self, k):\n",
    "        self.k=k \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.__X=X\n",
    "        self.__y=y\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions=np.zeros(X_test.shape[0],dtype=np.int32)\n",
    "        idx=0\n",
    "        for x in X_test:\n",
    "            distances=np.sqrt(np.sum((self.__X-x)**2,axis=-1))\n",
    "            k_indices=np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels=self.__y[k_indices]\n",
    "            unique,counts=np.unique(k_nearest_labels,return_counts=True)\n",
    "            max_count=np.max(counts)\n",
    "            candidates=unique[counts==max_count]\n",
    "            if len(candidates)>1:\n",
    "                predicted_label=np.random.choice(candidates)\n",
    "            else:\n",
    "                predicted_label=candidates[0]\n",
    "            predictions[idx]=predicted_label\n",
    "            idx+=1\n",
    "        return predictions\n",
    "knn = kNearestNeighbor(num_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "test_data=pd.read_csv('./test-knn.csv')\n",
    "X_test=test_data.drop(columns=['class']).to_numpy()\n",
    "y_test=test_data.pop('class').to_numpy()\n",
    "predictions = knn.predict(X_test)\n",
    "print(np.sum(predictions==y_test)/y_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii\\. Perform cross-validation (with 5 folds) on the train dataset __train-knn.csv__ to determine a suitable value of K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The suitable value of K is 11\n"
     ]
    }
   ],
   "source": [
    "def kfold_indices(data, k):\n",
    "    fold_size = len(data) // k\n",
    "    indices = np.arange(len(data))\n",
    "    folds = []\n",
    "    for i in range(k):\n",
    "        test_indices = indices[i * fold_size: (i + 1) * fold_size]\n",
    "        train_indices = np.concatenate([indices[:i * fold_size], indices[(i + 1) * fold_size:]])\n",
    "        folds.append((train_indices, test_indices))\n",
    "    return folds\n",
    "\n",
    "# Define the number of folds (K)\n",
    "k = 5\n",
    "K_values=np.array(range(1,21))\n",
    "# Get the fold indices\n",
    "fold_indices = kfold_indices(X_train, k)\n",
    "mean_accuracies=[]\n",
    "for K in K_values:\n",
    "    model=kNearestNeighbor(K)\n",
    "    fold_accuracies=[]\n",
    "    for train_indices,test_indices in fold_indices:\n",
    "        X_train_cv,y_train_cv=X_train[train_indices],y_train[train_indices]\n",
    "        X_test_cv,y_test_cv=X_train[test_indices],y_train[test_indices]\n",
    "        model.fit(X_train_cv,y_train_cv)\n",
    "        y_pred_cv=model.predict(X_test_cv)\n",
    "        fold_accuracy=np.sum(y_pred_cv==y_test_cv)/y_test_cv.size\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "    mean_accuracies.append(np.mean(np.array(fold_accuracies)))\n",
    "optimal_k=K_values[np.argmax(mean_accuracies)]\n",
    "print(f\"The suitable value of K is {optimal_k}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii\\. Using the optimal value of k from the cross-validation, obtain the accuracy of your model on the test dataset __test-knn.csv__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 77.0%\n"
     ]
    }
   ],
   "source": [
    "knn_opt=kNearestNeighbor(11)\n",
    "knn_opt.fit(X_train,y_train)\n",
    "predictions_opt=knn_opt.predict(X_test)\n",
    "Accuracy=np.sum(predictions_opt==y_test)/y_test.size\n",
    "print(f\"The accuracy of the model is {Accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv\\. Compare your result with the KNeighborsClassifier model from the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 77.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_sklearn=KNeighborsClassifier(n_neighbors=11)\n",
    "knn_sklearn.fit(X_train,y_train)\n",
    "predictions_sklearn=knn_sklearn.predict(X_test)\n",
    "Accuracy_sk=np.sum(predictions_sklearn==y_test)/y_test.size\n",
    "print(f\"The accuracy of the model is {Accuracy_sk*100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v\\. How do the bias and variance of each model vary as K increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias increases with increasing K and variance decreases with increasing K"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
